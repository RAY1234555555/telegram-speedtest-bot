import base64
import json
import logging
import urllib.parse
import requests
import re
from typing import Dict, List, Optional, Union

logger = logging.getLogger(__name__)

def parse_vmess_link(link: str) -> Optional[Dict]:
    """è§£æ vmess:// é“¾æ¥"""
    if not link.startswith("vmess://"):
        return None

    try:
        encoded_data = link[len("vmess://"):].strip()
        # æ·»åŠ å¡«å……ä»¥ç¡®ä¿æ­£ç¡®çš„base64è§£ç 
        missing_padding = len(encoded_data) % 4
        if missing_padding:
            encoded_data += '=' * (4 - missing_padding)
            
        decoded_data = base64.b64decode(encoded_data).decode('utf-8')
        node_info = json.loads(decoded_data)

        parsed_node = {
            "name": node_info.get("ps", "Unknown VMess Node"),
            "server": node_info.get("add"),
            "port": int(node_info.get("port", 443)),
            "uuid": node_info.get("id"),
            "alterId": int(node_info.get("aid", 0)),
            "protocol": "vmess",
            "tls": node_info.get("tls", ""),
            "network": node_info.get("net", "tcp"),
            "security": node_info.get("scy", "auto"),
            "host": node_info.get("host", ""),
            "path": node_info.get("path", ""),
            "type": node_info.get("type", "none"),
            "sni": node_info.get("sni", ""),
            "alpn": node_info.get("alpn", ""),
            "fp": node_info.get("fp", "")
        }

        if not all([parsed_node["server"], parsed_node["port"], parsed_node["uuid"]]):
            logger.warning(f"VMess link missing essential fields: {link[:50]}...")
            return None

        logger.info(f"Successfully parsed VMess node: {parsed_node['name']}")
        return parsed_node

    except Exception as e:
        logger.error(f"Error parsing VMess link: {e}")
        return None

def parse_vless_link(link: str) -> Optional[Dict]:
    """è§£æ vless:// é“¾æ¥"""
    if not link.startswith("vless://"):
        return None

    try:
        # vless://uuid@server:port?encryption=none&flow=xtls-rprx-vision&security=reality&sni=www.microsoft.com&fp=safari&pbk=...#name
        url_parts = urllib.parse.urlparse(link)
        query_params = urllib.parse.parse_qs(url_parts.query)
        
        # ä»fragmentä¸­è·å–èŠ‚ç‚¹åç§°
        name = urllib.parse.unquote(url_parts.fragment) if url_parts.fragment else "Unknown VLess Node"
        
        parsed_node = {
            "name": name,
            "server": url_parts.hostname,
            "port": int(url_parts.port or 443),
            "uuid": url_parts.username,
            "protocol": "vless",
            "encryption": query_params.get("encryption", ["none"])[0],
            "flow": query_params.get("flow", [""])[0],
            "security": query_params.get("security", ["none"])[0],
            "sni": query_params.get("sni", [""])[0],
            "fp": query_params.get("fp", [""])[0],
            "pbk": query_params.get("pbk", [""])[0],
            "sid": query_params.get("sid", [""])[0],
            "type": query_params.get("type", ["tcp"])[0],
            "host": query_params.get("host", [""])[0],
            "path": query_params.get("path", [""])[0],
            "headerType": query_params.get("headerType", ["none"])[0],
            "alpn": query_params.get("alpn", [""])[0]
        }

        if not all([parsed_node["server"], parsed_node["port"], parsed_node["uuid"]]):
            logger.warning(f"VLess link missing essential fields: {link[:50]}...")
            return None

        logger.info(f"Successfully parsed VLess node: {parsed_node['name']}")
        return parsed_node

    except Exception as e:
        logger.error(f"Error parsing VLess link: {e}")
        return None

def parse_shadowsocks_link(link: str) -> Optional[Dict]:
    """è§£æ ss:// é“¾æ¥"""
    if not link.startswith("ss://"):
        return None

    try:
        # ss://method:password@server:port#name æˆ– ss://base64encoded#name
        url_parts = urllib.parse.urlparse(link)
        
        if url_parts.username and url_parts.password:
            # æ–°æ ¼å¼: ss://method:password@server:port#name
            method = url_parts.username
            password = url_parts.password
        else:
            # æ—§æ ¼å¼: ss://base64encoded@server:port#name æˆ– ss://base64encoded#name
            if '@' in link:
                encoded_part = link[5:].split('@')[0]
            else:
                encoded_part = link[5:].split('#')[0]
            
            # æ·»åŠ å¡«å……
            missing_padding = len(encoded_part) % 4
            if missing_padding:
                encoded_part += '=' * (4 - missing_padding)
                
            try:
                decoded = base64.b64decode(encoded_part).decode('utf-8')
                if ':' in decoded:
                    method, password = decoded.split(':', 1)
                else:
                    method, password = "aes-256-gcm", decoded
            except:
                logger.error(f"Failed to decode SS credentials: {encoded_part}")
                return None
        
        name = urllib.parse.unquote(url_parts.fragment) if url_parts.fragment else "Unknown SS Node"
        
        parsed_node = {
            "name": name,
            "server": url_parts.hostname,
            "port": int(url_parts.port or 8388),
            "method": method,
            "password": password,
            "protocol": "shadowsocks",
            "plugin": "",
            "plugin_opts": ""
        }

        if not all([parsed_node["server"], parsed_node["port"], parsed_node["method"], parsed_node["password"]]):
            logger.warning(f"Shadowsocks link missing essential fields: {link[:50]}...")
            return None

        logger.info(f"Successfully parsed Shadowsocks node: {parsed_node['name']}")
        return parsed_node

    except Exception as e:
        logger.error(f"Error parsing Shadowsocks link: {e}")
        return None

def parse_hysteria2_link(link: str) -> Optional[Dict]:
    """è§£æ hy2:// æˆ– hysteria2:// é“¾æ¥"""
    if not (link.startswith("hy2://") or link.startswith("hysteria2://")):
        return None

    try:
        url_parts = urllib.parse.urlparse(link)
        query_params = urllib.parse.parse_qs(url_parts.query)
        
        name = urllib.parse.unquote(url_parts.fragment) if url_parts.fragment else "Unknown Hysteria2 Node"
        
        parsed_node = {
            "name": name,
            "server": url_parts.hostname,
            "port": int(url_parts.port or 443),
            "password": url_parts.username or query_params.get("auth", [""])[0],
            "protocol": "hysteria2",
            "sni": query_params.get("sni", [""])[0],
            "insecure": query_params.get("insecure", ["0"])[0] == "1",
            "obfs": query_params.get("obfs", [""])[0],
            "obfs_password": query_params.get("obfs-password", [""])[0],
            "up": query_params.get("up", [""])[0],
            "down": query_params.get("down", [""])[0]
        }

        if not all([parsed_node["server"], parsed_node["port"]]):
            logger.warning(f"Hysteria2 link missing essential fields: {link[:50]}...")
            return None

        logger.info(f"Successfully parsed Hysteria2 node: {parsed_node['name']}")
        return parsed_node

    except Exception as e:
        logger.error(f"Error parsing Hysteria2 link: {e}")
        return None

def parse_trojan_link(link: str) -> Optional[Dict]:
    """è§£æ trojan:// é“¾æ¥"""
    if not link.startswith("trojan://"):
        return None

    try:
        url_parts = urllib.parse.urlparse(link)
        query_params = urllib.parse.parse_qs(url_parts.query)
        
        name = urllib.parse.unquote(url_parts.fragment) if url_parts.fragment else "Unknown Trojan Node"
        
        parsed_node = {
            "name": name,
            "server": url_parts.hostname,
            "port": int(url_parts.port or 443),
            "password": url_parts.username,
            "protocol": "trojan",
            "sni": query_params.get("sni", [""])[0],
            "type": query_params.get("type", ["tcp"])[0],
            "host": query_params.get("host", [""])[0],
            "path": query_params.get("path", [""])[0],
            "security": query_params.get("security", ["tls"])[0],
            "alpn": query_params.get("alpn", [""])[0],
            "fp": query_params.get("fp", [""])[0]
        }

        if not all([parsed_node["server"], parsed_node["port"], parsed_node["password"]]):
            logger.warning(f"Trojan link missing essential fields: {link[:50]}...")
            return None

        logger.info(f"Successfully parsed Trojan node: {parsed_node['name']}")
        return parsed_node

    except Exception as e:
        logger.error(f"Error parsing Trojan link: {e}")
        return None

def parse_single_node(link: str) -> Optional[Dict]:
    """è§£æå•ä¸ªèŠ‚ç‚¹é“¾æ¥"""
    link = link.strip()
    
    if link.startswith("vmess://"):
        return parse_vmess_link(link)
    elif link.startswith("vless://"):
        return parse_vless_link(link)
    elif link.startswith("ss://"):
        return parse_shadowsocks_link(link)
    elif link.startswith(("hy2://", "hysteria2://")):
        return parse_hysteria2_link(link)
    elif link.startswith("trojan://"):
        return parse_trojan_link(link)
    else:
        logger.warning(f"Unsupported protocol: {link[:20]}...")
        return None

def fetch_subscription(url: str, timeout: int = 15) -> Optional[str]:
    """è·å–è®¢é˜…å†…å®¹"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        response = requests.get(url, headers=headers, timeout=timeout, verify=False)
        response.raise_for_status()
        
        logger.info(f"Successfully fetched subscription, content length: {len(response.text)}")
        return response.text
        
    except requests.exceptions.Timeout:
        logger.error(f"Subscription fetch timeout: {url}")
        return None
    except requests.exceptions.RequestException as e:
        logger.error(f"Failed to fetch subscription {url}: {e}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error fetching subscription {url}: {e}")
        return None

def parse_subscription_content(content: str) -> List[Dict]:
    """è§£æè®¢é˜…å†…å®¹"""
    nodes = []
    
    try:
        # å°è¯•base64è§£ç 
        try:
            decoded_content = base64.b64decode(content).decode('utf-8')
            content = decoded_content
            logger.info("Successfully decoded base64 subscription content")
        except:
            logger.info("Subscription content is not base64 encoded, using as-is")
        
        # æŒ‰è¡Œåˆ†å‰²å¹¶è§£ææ¯ä¸ªèŠ‚ç‚¹
        lines = content.strip().split('\n')
        logger.info(f"Processing {len(lines)} lines from subscription")
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
                
            node = parse_single_node(line)
            if node:
                nodes.append(node)
                logger.debug(f"Parsed node {i+1}: {node['name']}")
            else:
                logger.debug(f"Failed to parse line {i+1}: {line[:50]}...")
    
    except Exception as e:
        logger.error(f"Error parsing subscription content: {e}")
    
    logger.info(f"Successfully parsed {len(nodes)} nodes from subscription")
    return nodes

def parse_subscription_link(sub_link: str) -> List[Dict]:
    """è§£æè®¢é˜…é“¾æ¥"""
    nodes = []
    logger.info(f"Attempting to parse subscription: {sub_link[:100]}...")
    
    if sub_link.startswith(("http://", "https://")):
        # è·å–è®¢é˜…å†…å®¹
        content = fetch_subscription(sub_link)
        if content:
            nodes = parse_subscription_content(content)
        else:
            logger.error("Failed to fetch subscription content")
    else:
        # å°è¯•ä½œä¸ºå•ä¸ªèŠ‚ç‚¹è§£æ
        node = parse_single_node(sub_link)
        if node:
            nodes.append(node)
    
    logger.info(f"Final result: {len(nodes)} nodes parsed from subscription")
    return nodes

def get_node_info_summary(node: Dict) -> str:
    """è·å–èŠ‚ç‚¹ä¿¡æ¯æ‘˜è¦"""
    protocol = node.get('protocol', 'unknown').upper()
    name = node.get('name', 'Unknown Node')
    server = node.get('server', 'unknown')
    port = node.get('port', 'unknown')
    
    summary = f"ğŸ“¡ **{name}**\n"
    summary += f"ğŸ”— åè®®: {protocol}\n"
    summary += f"ğŸŒ æœåŠ¡å™¨: `{server}:{port}`\n"
    
    if protocol == "VMESS":
        summary += f"ğŸ”‘ UUID: `{node.get('uuid', 'N/A')[:8]}...`\n"
        summary += f"ğŸ›¡ï¸ åŠ å¯†: {node.get('security', 'auto')}\n"
        summary += f"ğŸŒ ç½‘ç»œ: {node.get('network', 'tcp')}\n"
        if node.get('tls'):
            summary += f"ğŸ”’ TLS: {node.get('tls')}\n"
        if node.get('sni'):
            summary += f"ğŸ·ï¸ SNI: {node.get('sni')}\n"
    elif protocol == "VLESS":
        summary += f"ğŸ”‘ UUID: `{node.get('uuid', 'N/A')[:8]}...`\n"
        summary += f"ğŸ”’ å®‰å…¨: {node.get('security', 'none')}\n"
        if node.get('flow'):
            summary += f"ğŸŒŠ æµæ§: {node.get('flow')}\n"
        if node.get('sni'):
            summary += f"ğŸ·ï¸ SNI: {node.get('sni')}\n"
    elif protocol == "SHADOWSOCKS":
        summary += f"ğŸ” åŠ å¯†: {node.get('method', 'N/A')}\n"
        summary += f"ğŸ”‘ å¯†ç : `{node.get('password', 'N/A')[:8]}...`\n"
    elif protocol == "HYSTERIA2":
        summary += f"ğŸ” è®¤è¯: {'æ˜¯' if node.get('password') else 'å¦'}\n"
        if node.get('sni'):
            summary += f"ğŸ·ï¸ SNI: {node.get('sni')}\n"
        if node.get('obfs'):
            summary += f"ğŸ­ æ··æ·†: {node.get('obfs')}\n"
    elif protocol == "TROJAN":
        summary += f"ğŸ”‘ å¯†ç : `{node.get('password', 'N/A')[:8]}...`\n"
        if node.get('sni'):
            summary += f"ğŸ·ï¸ SNI: {node.get('sni')}\n"
        summary += f"ğŸ”’ å®‰å…¨: {node.get('security', 'tls')}\n"
    
    return summary

def detect_region_from_server(server: str) -> str:
    """æ ¹æ®æœåŠ¡å™¨åœ°å€æ£€æµ‹åœ°åŒº"""
    server = server.lower()
    
    # å¸¸è§åœ°åŒºå…³é”®è¯æ˜ å°„
    region_keywords = {
        'ğŸ‡ºğŸ‡¸ ç¾å›½': ['us', 'usa', 'america', 'united', 'states', 'california', 'newyork', 'texas', 'virginia'],
        'ğŸ‡¯ğŸ‡µ æ—¥æœ¬': ['jp', 'japan', 'tokyo', 'osaka', 'kyoto'],
        'ğŸ‡­ğŸ‡° é¦™æ¸¯': ['hk', 'hongkong', 'hong-kong'],
        'ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡': ['sg', 'singapore', 'singapur'],
        'ğŸ‡©ğŸ‡ª å¾·å›½': ['de', 'germany', 'deutsch', 'berlin', 'frankfurt'],
        'ğŸ‡¬ğŸ‡§ è‹±å›½': ['uk', 'britain', 'england', 'london'],
        'ğŸ‡«ğŸ‡· æ³•å›½': ['fr', 'france', 'paris'],
        'ğŸ‡¨ğŸ‡¦ åŠ æ‹¿å¤§': ['ca', 'canada', 'toronto', 'vancouver'],
        'ğŸ‡¦ğŸ‡º æ¾³å¤§åˆ©äºš': ['au', 'australia', 'sydney', 'melbourne'],
        'ğŸ‡°ğŸ‡· éŸ©å›½': ['kr', 'korea', 'seoul'],
        'ğŸ‡³ğŸ‡± è·å…°': ['nl', 'netherlands', 'amsterdam'],
        'ğŸ‡·ğŸ‡º ä¿„ç½—æ–¯': ['ru', 'russia', 'moscow'],
        'ğŸ‡®ğŸ‡³ å°åº¦': ['in', 'india', 'mumbai', 'delhi'],
        'ğŸ‡§ğŸ‡· å·´è¥¿': ['br', 'brazil', 'sao', 'paulo'],
        'ğŸ‡¹ğŸ‡¼ å°æ¹¾': ['tw', 'taiwan', 'taipei'],
        'ğŸ‡¹ğŸ‡­ æ³°å›½': ['th', 'thailand', 'bangkok'],
        'ğŸ‡²ğŸ‡¾ é©¬æ¥è¥¿äºš': ['my', 'malaysia', 'kuala', 'lumpur'],
        'ğŸ‡µğŸ‡­ è²å¾‹å®¾': ['ph', 'philippines', 'manila'],
        'ğŸ‡»ğŸ‡³ è¶Šå—': ['vn', 'vietnam', 'hanoi', 'saigon'],
        'ğŸ‡®ğŸ‡© å°å°¼': ['id', 'indonesia', 'jakarta'],
        'ğŸ‡¦ğŸ‡ª é˜¿è”é…‹': ['ae', 'uae', 'dubai', 'emirates'],
        'ğŸ‡¹ğŸ‡· åœŸè€³å…¶': ['tr', 'turkey', 'istanbul'],
        'ğŸ‡®ğŸ‡± ä»¥è‰²åˆ—': ['il', 'israel', 'telaviv'],
        'ğŸ‡¿ğŸ‡¦ å—é': ['za', 'south', 'africa', 'cape', 'town'],
        'ğŸ‡¦ğŸ‡· é˜¿æ ¹å»·': ['ar', 'argentina', 'buenos', 'aires'],
        'ğŸ‡¨ğŸ‡± æ™ºåˆ©': ['cl', 'chile', 'santiago'],
        'ğŸ‡²ğŸ‡½ å¢¨è¥¿å“¥': ['mx', 'mexico', 'mexico', 'city'],
        'ğŸ‡ªğŸ‡¸ è¥¿ç­ç‰™': ['es', 'spain', 'madrid', 'barcelona'],
        'ğŸ‡®ğŸ‡¹ æ„å¤§åˆ©': ['it', 'italy', 'rome', 'milan'],
        'ğŸ‡¨ğŸ‡­ ç‘å£«': ['ch', 'switzerland', 'zurich', 'geneva'],
        'ğŸ‡¸ğŸ‡ª ç‘å…¸': ['se', 'sweden', 'stockholm'],
        'ğŸ‡³ğŸ‡´ æŒªå¨': ['no', 'norway', 'oslo'],
        'ğŸ‡©ğŸ‡° ä¸¹éº¦': ['dk', 'denmark', 'copenhagen'],
        'ğŸ‡«ğŸ‡® èŠ¬å…°': ['fi', 'finland', 'helsinki'],
        'ğŸ‡µğŸ‡± æ³¢å…°': ['pl', 'poland', 'warsaw'],
        'ğŸ‡¨ğŸ‡¿ æ·å…‹': ['cz', 'czech', 'prague'],
        'ğŸ‡¦ğŸ‡¹ å¥¥åœ°åˆ©': ['at', 'austria', 'vienna'],
        'ğŸ‡§ğŸ‡ª æ¯”åˆ©æ—¶': ['be', 'belgium', 'brussels'],
        'ğŸ‡µğŸ‡¹ è‘¡è„ç‰™': ['pt', 'portugal', 'lisbon'],
        'ğŸ‡¬ğŸ‡· å¸Œè…Š': ['gr', 'greece', 'athens'],
        'ğŸ‡­ğŸ‡º åŒˆç‰™åˆ©': ['hu', 'hungary', 'budapest'],
        'ğŸ‡·ğŸ‡´ ç½—é©¬å°¼äºš': ['ro', 'romania', 'bucharest'],
        'ğŸ‡§ğŸ‡¬ ä¿åŠ åˆ©äºš': ['bg', 'bulgaria', 'sofia'],
        'ğŸ‡­ğŸ‡· å…‹ç½—åœ°äºš': ['hr', 'croatia', 'zagreb'],
        'ğŸ‡¸ğŸ‡® æ–¯æ´›æ–‡å°¼äºš': ['si', 'slovenia', 'ljubljana'],
        'ğŸ‡¸ğŸ‡° æ–¯æ´›ä¼å…‹': ['sk', 'slovakia', 'bratislava'],
        'ğŸ‡±ğŸ‡¹ ç«‹é™¶å®›': ['lt', 'lithuania', 'vilnius'],
        'ğŸ‡±ğŸ‡» æ‹‰è„±ç»´äºš': ['lv', 'latvia', 'riga'],
        'ğŸ‡ªğŸ‡ª çˆ±æ²™å°¼äºš': ['ee', 'estonia', 'tallinn'],
        'ğŸ‡ºğŸ‡¦ ä¹Œå…‹å…°': ['ua', 'ukraine', 'kiev', 'kyiv'],
        'ğŸ‡§ğŸ‡¾ ç™½ä¿„ç½—æ–¯': ['by', 'belarus', 'minsk'],
        'ğŸ‡²ğŸ‡© æ‘©å°”å¤šç“¦': ['md', 'moldova', 'chisinau'],
        'ğŸ‡·ğŸ‡¸ å¡å°”ç»´äºš': ['rs', 'serbia', 'belgrade'],
        'ğŸ‡²ğŸ‡ª é»‘å±±': ['me', 'montenegro', 'podgorica'],
        'ğŸ‡§ğŸ‡¦ æ³¢é»‘': ['ba', 'bosnia', 'sarajevo'],
        'ğŸ‡²ğŸ‡° åŒ—é©¬å…¶é¡¿': ['mk', 'macedonia', 'skopje'],
        'ğŸ‡¦ğŸ‡± é˜¿å°”å·´å°¼äºš': ['al', 'albania', 'tirana'],
        'ğŸ‡½ğŸ‡° ç§‘ç´¢æ²ƒ': ['xk', 'kosovo', 'pristina'],
        'ğŸ‡¨ğŸ‡³ ä¸­å›½': ['cn', 'china', 'beijing', 'shanghai', 'guangzhou', 'shenzhen']
    }
    
    for region, keywords in region_keywords.items():
        for keyword in keywords:
            if keyword in server:
                return region
    
    return 'ğŸŒ æœªçŸ¥åœ°åŒº'

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # æµ‹è¯•å„ç§åè®®
    test_links = [
        "vmess://eyJhZGQiOiIxLjIuMy40IiwicG9ydCI6NDQzLCJpZCI6ImExYjJjM2Q0LWU1ZjYtNzg5MC0xMjM0LTU2Nzg5MGFiY2RlZiIsImFpZCI6MiwibmV0Ijoid3MiLCJob3N0IjoiZXhhbXBsZS5jb20iLCJwYXRoIjoiL3dlYnNvY2tldCIsInRscyI6InRscyIsInBzIjoiVGVzdCBWTWVzcyIsInNjeSI6ImF1dG8iLCJ0eXBlIjoiYXV0byJ9",
        "vless://uuid@example.com:443?encryption=none&flow=xtls-rprx-vision&security=reality&sni=www.microsoft.com&fp=safari#Test%20VLess",
        "ss://YWVzLTI1Ni1nY206cGFzc3dvcmQ@example.com:8388#Test%20SS",
        "hy2://password@example.com:443?sni=example.com#Test%20Hysteria2",
        "trojan://password@example.com:443?sni=example.com#Test%20Trojan"
    ]
    
    for link in test_links:
        print(f"\n--- Testing: {link[:50]}... ---")
        node = parse_single_node(link)
        if node:
            print(get_node_info_summary(node))
        else:
            print("Failed to parse")
